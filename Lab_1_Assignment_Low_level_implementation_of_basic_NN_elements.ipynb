{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lTnqOc-r0Wy"
      },
      "source": [
        "<h1 align=\"center\">UST, Zewail City</h1>\n",
        "<h2 align=\"center\">CIE 555 (Spring 2021)</h2>\n",
        "<h2 align=\"center\">Lab 1: Neural Network Implementation </h2>\n",
        "<h3 align=\"center\">Aya Elzahy</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtaFsemWr2lb"
      },
      "source": [
        "This notebook is based on Udacity Deep Learning Nanodegree \n",
        "\n",
        "https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-bikesharing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcoEArqvsASz"
      },
      "source": [
        "#Lab objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvjZztFDsEiZ"
      },
      "source": [
        "In this lab, you will learn how to build the basic operations of a typical neural network from scratch. Network will be trained and validated using a synthetic regression dataset that we generate as part of this exercise. Learning objectives are:\n",
        "\n",
        "*   Understand the computational model of a neuron\n",
        "*   Implement the basic operations of a typical neural network.\n",
        "*   Understand the notion of backpropagation and how it is used to train neural networks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkQsWLbIsPv7"
      },
      "source": [
        "#Import statements "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkV0IlZOsYpm"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "random.seed(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIB7ZYiNsbn9"
      },
      "source": [
        "#Synthesize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0UxU2StuOIt"
      },
      "source": [
        "In this step, we generate synthetic regression data that has 200 samples and 2 features. Our neural network model will be trained and tested using this data.\n",
        "\n",
        "To use the data in our modelling exercise, we need to scale the data to have a zero mean and unit standard deviation. Scaling the data is a typical practice in neural networks' modelling to make the learning process stable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utkTsJmWsnFs"
      },
      "source": [
        "x_data,y_data = make_regression(n_samples=200, n_features=2)\n",
        "\n",
        "train_features,val_features, train_targets,val_targets=train_test_split(x_data,y_data,test_size=0.2)\n",
        "\n",
        "#Fitting the scaler to training data only to prevent data leakage\n",
        "feature_scaler= StandardScaler().fit(train_features)\n",
        "train_features= feature_scaler.transform(train_features)\n",
        "val_features= feature_scaler.transform(val_features)\n",
        "\n",
        "target_scaler= StandardScaler().fit(train_targets.reshape(-1, 1))\n",
        "train_targets=target_scaler.transform(train_targets.reshape(-1, 1))\n",
        "val_targets=target_scaler.transform(val_targets.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL7BuPtFtpiA",
        "outputId": "ff7e400e-df0e-46b7-aaad-14ac03bf14c6"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(val_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(160, 2)\n",
            "(40, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1_uyE62vDp_"
      },
      "source": [
        "#Build a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXN6nCH6vKl7"
      },
      "source": [
        "In this task, will write the basic functions of a typical neural network. The network we use in this exercise has the following architecture: \n",
        "* Two input nodes corresponding to the 2 input features.\n",
        "* Three hidden nodes in the hidden layer. All nodes in the hidden layer use ReLU activation. 'hi' is the input to the hidden layer that is the sum of w0 multiplied by the input nodes in the forward pass step. 'ho' is the output of the hidden nodes that equals to ReLU (hi). \n",
        "* One output node corresponding to the target variable in the dataset. This node doesn't use any non-linear activations. The input to the node (oi) is the sum of ho multiplied by the weights w1. The output of the node (oo) equals the input of the node(oi). \n",
        "\n",
        "\n",
        "An illustrative diagram of the network is shown below. The diagram is labeled with suggested variable names. We recommend you stick to these variable names while writing the code to avoid confusion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdJuoTN8mYyt"
      },
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0R3hHLoxYL6"
      },
      "source": [
        " When training the network, as you will see in the upcoming section, weights will be randomly initialized using a normal distribution. The network will be trained for a certain number of iterations that you specify as a hyperparameter. In each iteration we loop over the training samples performing forward and backward operations. Netowrk is optimized using a  batch gradient descent technique. That is, we use the average delta_weight_ih and delta_weight_h_o, calcualted using all training samples, to update the weights.\n",
        "\n",
        " Your task is to build these basic operations that will be used later in the model training.\n",
        "\n",
        "  1. Forward pass: you'll calculate the values of hi,ho,oi,oo in the function ***forward_pass*** [Task 1] and return the hidden outputs (ho) and final outputs (oo). You'll need to implement the activation in the dunction ***relu*** [Task 2] to use it for activating the input to the hidden units.\n",
        "  2. Backpropagation: You'll implement ***backpropagation*** function [Task 3] to calculate the change in weights from input to hidden layers (delta_weights_i_h) and change in weights from hidden to output layers (delta_weights_h_o). You'll need to implement ReLU derivative in the function **relu_deriv** [Task 4] to use it in backpropagation. You'll also need to implement the mean square error loss function (***MSE***) [Task 5]    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qSC4ungURO8"
      },
      "source": [
        "def relu (x):\n",
        "  y = np.maximum(0, x)\n",
        "  return y \n",
        "        \n",
        "def relu_deriv (x): \n",
        "  return ((x>0)*1)\n",
        "\n",
        "def MSE(y, Y):\n",
        "  return (0.5*np.sum((y-Y)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehU16Qu5VNNC"
      },
      "source": [
        "def forward_pass(X,w0,w1):\n",
        "        ''' Implement the forward pass of the two-layer netowrk shown above.  [3 marks]\n",
        "         \n",
        "            Arguments\n",
        "            ---------\n",
        "            X: feature sample with shape (2x1)\n",
        "            return the final output (oo) and hidden output(ho) as per the diagram\n",
        "            \n",
        "            Equations:\n",
        "            hi = X.transpose() . w0\n",
        "            ho = ReLu(hi)\n",
        "            oi = ho . w1\n",
        "            oo = oi\n",
        "\n",
        "         '''\n",
        "        ### Forward pass ###     \n",
        "        hi = np.matmul(X, w0)           #input to hidden layer\n",
        "        ho = relu(hi)                # output from hidden layer\n",
        "        oi = np.matmul(ho, w1)          #input to final output layer\n",
        "        oo = oi                      #output from final output layer with no activation \n",
        "        \n",
        "        return oo, ho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1c2JN9RVcDS"
      },
      "source": [
        "def backpropagation(oo, ho, X, y, delta_weights_i_h, delta_weights_h_o):\n",
        "        ''' Implement tha backward pass of the network shown above [4 marks]\n",
        "         \n",
        "            Arguments\n",
        "            ---------\n",
        "            oo: the final output of the network produced by the forward pass \n",
        "            ho: output the hidden layer of the network produced by produced by the forward pass function \n",
        "            X: feature sample with shape (2x1)\n",
        "            y: target label\n",
        "            delta_weights_i_h: change in weights from input to hidden layers\n",
        "            delta_weights_h_o: change in weights from hidden to output layers\n",
        "            \n",
        "            delta_weights_i_h and delta_weights_h_o accumlate the change values due to every single example. \n",
        "            In the training part at the end of the notebook, at the end of every iteration, we use these delta values to\n",
        "            update the weights(weights+=learning rate*delta_weights/number of training samples),\n",
        "            so don't update the weights in this function. just return the delta values. \n",
        "        '''\n",
        "        ### Backward pass ###\n",
        "        error =  y - oo\n",
        "        delta_weights_h_o += (ho * error).transpose()\n",
        "        delta_weights_i_h += (np.matmul(np.linalg.pinv(ho), oo) * relu_deriv(ho).transpose() * X * error).transpose()\n",
        "        \n",
        "        return delta_weights_i_h, delta_weights_h_o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "decgMWqE8gze"
      },
      "source": [
        "#Training the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXxrylVG8lWN"
      },
      "source": [
        "In this step, we will use the synthetic data that we generated earlier to train and test a neural network using the 'forward_pass' and 'backpropagation' functions you wrote earlier. As mentioned previously, weights will be randomly initialized using a normal distribution and they are updated using batch gradient descent. You don't have to change anything in the following cells. PLease run the code and check how the loss function is changing in each iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHv2qAfMVs2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a69da8d-3966-4952-8e0d-4531731eefbe"
      },
      "source": [
        "iterations = 1500  #You can change the number of iterations for better results \n",
        "lr = 0.1           #You can change the learning rate for better results \n",
        "hidden_nodes = 3 #Don't change\n",
        "output_nodes = 1 #Don't change \n",
        "input_nodes= train_features.shape[1] #Don't change\n",
        "n_records = train_features.shape[0]  #Don't change\n",
        "\n",
        "\n",
        "# Initialize weights\n",
        "#Weights are initialized randomly from a normal distribution\n",
        "w0 = np.random.normal(size= (input_nodes, hidden_nodes))  #Weights input to hidden\n",
        "\n",
        "w1 = np.random.normal(size= (hidden_nodes, output_nodes)) #weights hidden to output\n",
        "\n",
        "losses = {'train':[], 'validation':[]}\n",
        "for i in range(iterations):\n",
        "    delta_weights_i_h = np.zeros(w0.shape)\n",
        "    delta_weights_h_o = np.zeros(w1.shape)\n",
        "    for X, y in zip(train_features, train_targets):\n",
        "      X = X.reshape(1, -1)\n",
        "      y = y.reshape(1, -1)\n",
        "      oo, ho = forward_pass(X,w0,w1)  # Implement the forward pass function below  \n",
        "      delta_weights_i_h, delta_weights_h_o = backpropagation(oo, ho, X, y, delta_weights_i_h, delta_weights_h_o)\n",
        "\n",
        "    w1 += lr*delta_weights_h_o/n_records # update hidden-to-output weights with gradient descent step\n",
        "    w0 += lr*delta_weights_i_h/n_records # update input-to-hidden weights with gradient descent step\n",
        "\n",
        "    train_loss = MSE(forward_pass(train_features,w0,w1)[0], train_targets)\n",
        "    val_loss = MSE(forward_pass(val_features,w0,w1)[0], val_targets)\n",
        "    print(\"Iteration: \", i, \"...Training loss: \", round(train_loss,5), \"...Validation loss: \",  round(val_loss,5))    \n",
        "    losses['train'].append(train_loss)\n",
        "    losses['validation'].append(val_loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0 ...Training loss:  55.23627 ...Validation loss:  14.10032\n",
            "Iteration:  1 ...Training loss:  51.66245 ...Validation loss:  13.70759\n",
            "Iteration:  2 ...Training loss:  48.69964 ...Validation loss:  13.38644\n",
            "Iteration:  3 ...Training loss:  46.21146 ...Validation loss:  13.12056\n",
            "Iteration:  4 ...Training loss:  44.09438 ...Validation loss:  12.8864\n",
            "Iteration:  5 ...Training loss:  42.26765 ...Validation loss:  12.67347\n",
            "Iteration:  6 ...Training loss:  40.69141 ...Validation loss:  12.47621\n",
            "Iteration:  7 ...Training loss:  39.29152 ...Validation loss:  12.2834\n",
            "Iteration:  8 ...Training loss:  38.02671 ...Validation loss:  12.09125\n",
            "Iteration:  9 ...Training loss:  36.85593 ...Validation loss:  11.8928\n",
            "Iteration:  10 ...Training loss:  35.76156 ...Validation loss:  11.68943\n",
            "Iteration:  11 ...Training loss:  34.68123 ...Validation loss:  11.46739\n",
            "Iteration:  12 ...Training loss:  33.64396 ...Validation loss:  11.2357\n",
            "Iteration:  13 ...Training loss:  32.63956 ...Validation loss:  10.98385\n",
            "Iteration:  14 ...Training loss:  31.64685 ...Validation loss:  10.7354\n",
            "Iteration:  15 ...Training loss:  30.65149 ...Validation loss:  10.48154\n",
            "Iteration:  16 ...Training loss:  29.6878 ...Validation loss:  10.22704\n",
            "Iteration:  17 ...Training loss:  28.74744 ...Validation loss:  9.96843\n",
            "Iteration:  18 ...Training loss:  27.80732 ...Validation loss:  9.698\n",
            "Iteration:  19 ...Training loss:  26.85321 ...Validation loss:  9.41289\n",
            "Iteration:  20 ...Training loss:  25.8856 ...Validation loss:  9.11594\n",
            "Iteration:  21 ...Training loss:  24.92977 ...Validation loss:  8.81162\n",
            "Iteration:  22 ...Training loss:  23.98136 ...Validation loss:  8.50457\n",
            "Iteration:  23 ...Training loss:  23.04165 ...Validation loss:  8.19001\n",
            "Iteration:  24 ...Training loss:  22.11162 ...Validation loss:  7.87548\n",
            "Iteration:  25 ...Training loss:  21.1928 ...Validation loss:  7.56164\n",
            "Iteration:  26 ...Training loss:  20.28694 ...Validation loss:  7.24951\n",
            "Iteration:  27 ...Training loss:  19.39676 ...Validation loss:  6.94009\n",
            "Iteration:  28 ...Training loss:  18.52514 ...Validation loss:  6.63442\n",
            "Iteration:  29 ...Training loss:  17.66992 ...Validation loss:  6.33042\n",
            "Iteration:  30 ...Training loss:  16.82733 ...Validation loss:  6.02889\n",
            "Iteration:  31 ...Training loss:  16.00223 ...Validation loss:  5.73417\n",
            "Iteration:  32 ...Training loss:  15.19797 ...Validation loss:  5.44727\n",
            "Iteration:  33 ...Training loss:  14.42445 ...Validation loss:  5.1691\n",
            "Iteration:  34 ...Training loss:  13.68364 ...Validation loss:  4.90046\n",
            "Iteration:  35 ...Training loss:  12.97099 ...Validation loss:  4.64207\n",
            "Iteration:  36 ...Training loss:  12.28894 ...Validation loss:  4.39455\n",
            "Iteration:  37 ...Training loss:  11.63845 ...Validation loss:  4.15833\n",
            "Iteration:  38 ...Training loss:  11.02204 ...Validation loss:  3.93379\n",
            "Iteration:  39 ...Training loss:  10.43816 ...Validation loss:  3.72111\n",
            "Iteration:  40 ...Training loss:  9.88252 ...Validation loss:  3.52022\n",
            "Iteration:  41 ...Training loss:  9.35876 ...Validation loss:  3.33126\n",
            "Iteration:  42 ...Training loss:  8.86054 ...Validation loss:  3.15414\n",
            "Iteration:  43 ...Training loss:  8.3916 ...Validation loss:  2.98873\n",
            "Iteration:  44 ...Training loss:  7.95478 ...Validation loss:  2.83073\n",
            "Iteration:  45 ...Training loss:  7.54819 ...Validation loss:  2.68395\n",
            "Iteration:  46 ...Training loss:  7.17047 ...Validation loss:  2.54793\n",
            "Iteration:  47 ...Training loss:  6.82017 ...Validation loss:  2.42215\n",
            "Iteration:  48 ...Training loss:  6.49571 ...Validation loss:  2.30607\n",
            "Iteration:  49 ...Training loss:  6.19552 ...Validation loss:  2.19895\n",
            "Iteration:  50 ...Training loss:  5.91557 ...Validation loss:  2.09776\n",
            "Iteration:  51 ...Training loss:  5.65776 ...Validation loss:  2.00476\n",
            "Iteration:  52 ...Training loss:  5.41972 ...Validation loss:  1.91934\n",
            "Iteration:  53 ...Training loss:  5.19997 ...Validation loss:  1.84093\n",
            "Iteration:  54 ...Training loss:  4.99711 ...Validation loss:  1.76898\n",
            "Iteration:  55 ...Training loss:  4.8098 ...Validation loss:  1.70296\n",
            "Iteration:  56 ...Training loss:  4.63676 ...Validation loss:  1.64237\n",
            "Iteration:  57 ...Training loss:  4.47678 ...Validation loss:  1.58672\n",
            "Iteration:  58 ...Training loss:  4.32865 ...Validation loss:  1.53557\n",
            "Iteration:  59 ...Training loss:  4.19056 ...Validation loss:  1.4885\n",
            "Iteration:  60 ...Training loss:  4.06244 ...Validation loss:  1.44513\n",
            "Iteration:  61 ...Training loss:  3.94336 ...Validation loss:  1.4051\n",
            "Iteration:  62 ...Training loss:  3.83249 ...Validation loss:  1.36809\n",
            "Iteration:  63 ...Training loss:  3.72905 ...Validation loss:  1.33378\n",
            "Iteration:  64 ...Training loss:  3.63233 ...Validation loss:  1.30191\n",
            "Iteration:  65 ...Training loss:  3.54168 ...Validation loss:  1.27221\n",
            "Iteration:  66 ...Training loss:  3.45651 ...Validation loss:  1.24448\n",
            "Iteration:  67 ...Training loss:  3.37629 ...Validation loss:  1.21849\n",
            "Iteration:  68 ...Training loss:  3.30055 ...Validation loss:  1.19411\n",
            "Iteration:  69 ...Training loss:  3.22883 ...Validation loss:  1.17111\n",
            "Iteration:  70 ...Training loss:  3.16076 ...Validation loss:  1.14851\n",
            "Iteration:  71 ...Training loss:  3.09572 ...Validation loss:  1.12701\n",
            "Iteration:  72 ...Training loss:  3.03367 ...Validation loss:  1.1065\n",
            "Iteration:  73 ...Training loss:  2.97435 ...Validation loss:  1.08689\n",
            "Iteration:  74 ...Training loss:  2.9175 ...Validation loss:  1.06807\n",
            "Iteration:  75 ...Training loss:  2.86291 ...Validation loss:  1.04997\n",
            "Iteration:  76 ...Training loss:  2.81037 ...Validation loss:  1.03252\n",
            "Iteration:  77 ...Training loss:  2.75968 ...Validation loss:  1.01566\n",
            "Iteration:  78 ...Training loss:  2.7107 ...Validation loss:  0.99933\n",
            "Iteration:  79 ...Training loss:  2.6633 ...Validation loss:  0.98348\n",
            "Iteration:  80 ...Training loss:  2.61734 ...Validation loss:  0.96807\n",
            "Iteration:  81 ...Training loss:  2.57273 ...Validation loss:  0.95306\n",
            "Iteration:  82 ...Training loss:  2.52935 ...Validation loss:  0.93843\n",
            "Iteration:  83 ...Training loss:  2.48713 ...Validation loss:  0.92413\n",
            "Iteration:  84 ...Training loss:  2.44598 ...Validation loss:  0.91014\n",
            "Iteration:  85 ...Training loss:  2.40583 ...Validation loss:  0.89645\n",
            "Iteration:  86 ...Training loss:  2.36663 ...Validation loss:  0.88303\n",
            "Iteration:  87 ...Training loss:  2.32831 ...Validation loss:  0.86986\n",
            "Iteration:  88 ...Training loss:  2.29082 ...Validation loss:  0.85693\n",
            "Iteration:  89 ...Training loss:  2.25412 ...Validation loss:  0.84423\n",
            "Iteration:  90 ...Training loss:  2.21817 ...Validation loss:  0.83175\n",
            "Iteration:  91 ...Training loss:  2.18294 ...Validation loss:  0.81947\n",
            "Iteration:  92 ...Training loss:  2.14839 ...Validation loss:  0.80738\n",
            "Iteration:  93 ...Training loss:  2.11448 ...Validation loss:  0.79548\n",
            "Iteration:  94 ...Training loss:  2.0812 ...Validation loss:  0.78376\n",
            "Iteration:  95 ...Training loss:  2.04853 ...Validation loss:  0.77221\n",
            "Iteration:  96 ...Training loss:  2.01643 ...Validation loss:  0.76083\n",
            "Iteration:  97 ...Training loss:  1.98489 ...Validation loss:  0.74961\n",
            "Iteration:  98 ...Training loss:  1.95389 ...Validation loss:  0.73856\n",
            "Iteration:  99 ...Training loss:  1.92341 ...Validation loss:  0.72765\n",
            "Iteration:  100 ...Training loss:  1.89342 ...Validation loss:  0.7169\n",
            "Iteration:  101 ...Training loss:  1.86393 ...Validation loss:  0.70629\n",
            "Iteration:  102 ...Training loss:  1.83491 ...Validation loss:  0.69583\n",
            "Iteration:  103 ...Training loss:  1.80637 ...Validation loss:  0.6855\n",
            "Iteration:  104 ...Training loss:  1.77829 ...Validation loss:  0.67532\n",
            "Iteration:  105 ...Training loss:  1.75065 ...Validation loss:  0.66527\n",
            "Iteration:  106 ...Training loss:  1.72345 ...Validation loss:  0.65536\n",
            "Iteration:  107 ...Training loss:  1.69668 ...Validation loss:  0.64558\n",
            "Iteration:  108 ...Training loss:  1.67034 ...Validation loss:  0.63594\n",
            "Iteration:  109 ...Training loss:  1.6444 ...Validation loss:  0.62642\n",
            "Iteration:  110 ...Training loss:  1.61887 ...Validation loss:  0.61703\n",
            "Iteration:  111 ...Training loss:  1.59362 ...Validation loss:  0.60776\n",
            "Iteration:  112 ...Training loss:  1.56873 ...Validation loss:  0.59862\n",
            "Iteration:  113 ...Training loss:  1.54421 ...Validation loss:  0.58961\n",
            "Iteration:  114 ...Training loss:  1.52008 ...Validation loss:  0.58071\n",
            "Iteration:  115 ...Training loss:  1.49633 ...Validation loss:  0.57194\n",
            "Iteration:  116 ...Training loss:  1.47293 ...Validation loss:  0.56329\n",
            "Iteration:  117 ...Training loss:  1.44988 ...Validation loss:  0.55475\n",
            "Iteration:  118 ...Training loss:  1.42719 ...Validation loss:  0.54635\n",
            "Iteration:  119 ...Training loss:  1.40486 ...Validation loss:  0.53809\n",
            "Iteration:  120 ...Training loss:  1.38292 ...Validation loss:  0.52995\n",
            "Iteration:  121 ...Training loss:  1.36134 ...Validation loss:  0.52191\n",
            "Iteration:  122 ...Training loss:  1.34011 ...Validation loss:  0.51399\n",
            "Iteration:  123 ...Training loss:  1.31922 ...Validation loss:  0.50617\n",
            "Iteration:  124 ...Training loss:  1.29865 ...Validation loss:  0.49846\n",
            "Iteration:  125 ...Training loss:  1.27841 ...Validation loss:  0.49086\n",
            "Iteration:  126 ...Training loss:  1.25851 ...Validation loss:  0.48337\n",
            "Iteration:  127 ...Training loss:  1.23892 ...Validation loss:  0.47597\n",
            "Iteration:  128 ...Training loss:  1.21965 ...Validation loss:  0.46869\n",
            "Iteration:  129 ...Training loss:  1.20069 ...Validation loss:  0.4615\n",
            "Iteration:  130 ...Training loss:  1.18204 ...Validation loss:  0.45442\n",
            "Iteration:  131 ...Training loss:  1.16369 ...Validation loss:  0.44744\n",
            "Iteration:  132 ...Training loss:  1.14563 ...Validation loss:  0.44056\n",
            "Iteration:  133 ...Training loss:  1.12787 ...Validation loss:  0.43377\n",
            "Iteration:  134 ...Training loss:  1.11045 ...Validation loss:  0.42709\n",
            "Iteration:  135 ...Training loss:  1.09333 ...Validation loss:  0.4205\n",
            "Iteration:  136 ...Training loss:  1.07649 ...Validation loss:  0.41401\n",
            "Iteration:  137 ...Training loss:  1.05993 ...Validation loss:  0.40761\n",
            "Iteration:  138 ...Training loss:  1.04364 ...Validation loss:  0.40131\n",
            "Iteration:  139 ...Training loss:  1.02763 ...Validation loss:  0.3951\n",
            "Iteration:  140 ...Training loss:  1.01187 ...Validation loss:  0.38899\n",
            "Iteration:  141 ...Training loss:  0.99638 ...Validation loss:  0.38296\n",
            "Iteration:  142 ...Training loss:  0.98115 ...Validation loss:  0.37703\n",
            "Iteration:  143 ...Training loss:  0.96617 ...Validation loss:  0.37118\n",
            "Iteration:  144 ...Training loss:  0.95144 ...Validation loss:  0.36542\n",
            "Iteration:  145 ...Training loss:  0.93695 ...Validation loss:  0.35974\n",
            "Iteration:  146 ...Training loss:  0.92271 ...Validation loss:  0.35415\n",
            "Iteration:  147 ...Training loss:  0.9087 ...Validation loss:  0.34865\n",
            "Iteration:  148 ...Training loss:  0.89493 ...Validation loss:  0.34323\n",
            "Iteration:  149 ...Training loss:  0.88139 ...Validation loss:  0.33789\n",
            "Iteration:  150 ...Training loss:  0.86807 ...Validation loss:  0.33263\n",
            "Iteration:  151 ...Training loss:  0.85402 ...Validation loss:  0.32745\n",
            "Iteration:  152 ...Training loss:  0.8402 ...Validation loss:  0.32234\n",
            "Iteration:  153 ...Training loss:  0.8266 ...Validation loss:  0.31731\n",
            "Iteration:  154 ...Training loss:  0.81323 ...Validation loss:  0.31236\n",
            "Iteration:  155 ...Training loss:  0.80009 ...Validation loss:  0.30747\n",
            "Iteration:  156 ...Training loss:  0.78716 ...Validation loss:  0.30267\n",
            "Iteration:  157 ...Training loss:  0.77446 ...Validation loss:  0.29793\n",
            "Iteration:  158 ...Training loss:  0.76197 ...Validation loss:  0.29326\n",
            "Iteration:  159 ...Training loss:  0.74971 ...Validation loss:  0.28867\n",
            "Iteration:  160 ...Training loss:  0.73766 ...Validation loss:  0.28414\n",
            "Iteration:  161 ...Training loss:  0.72581 ...Validation loss:  0.27969\n",
            "Iteration:  162 ...Training loss:  0.71416 ...Validation loss:  0.2753\n",
            "Iteration:  163 ...Training loss:  0.70271 ...Validation loss:  0.27098\n",
            "Iteration:  164 ...Training loss:  0.69146 ...Validation loss:  0.26672\n",
            "Iteration:  165 ...Training loss:  0.68039 ...Validation loss:  0.26253\n",
            "Iteration:  166 ...Training loss:  0.66951 ...Validation loss:  0.25841\n",
            "Iteration:  167 ...Training loss:  0.65882 ...Validation loss:  0.25434\n",
            "Iteration:  168 ...Training loss:  0.64831 ...Validation loss:  0.25034\n",
            "Iteration:  169 ...Training loss:  0.63798 ...Validation loss:  0.2464\n",
            "Iteration:  170 ...Training loss:  0.62782 ...Validation loss:  0.24252\n",
            "Iteration:  171 ...Training loss:  0.61783 ...Validation loss:  0.23871\n",
            "Iteration:  172 ...Training loss:  0.60801 ...Validation loss:  0.23494\n",
            "Iteration:  173 ...Training loss:  0.59836 ...Validation loss:  0.23124\n",
            "Iteration:  174 ...Training loss:  0.58887 ...Validation loss:  0.22759\n",
            "Iteration:  175 ...Training loss:  0.57954 ...Validation loss:  0.224\n",
            "Iteration:  176 ...Training loss:  0.57037 ...Validation loss:  0.22047\n",
            "Iteration:  177 ...Training loss:  0.56135 ...Validation loss:  0.21699\n",
            "Iteration:  178 ...Training loss:  0.55248 ...Validation loss:  0.21356\n",
            "Iteration:  179 ...Training loss:  0.54376 ...Validation loss:  0.21018\n",
            "Iteration:  180 ...Training loss:  0.53519 ...Validation loss:  0.20686\n",
            "Iteration:  181 ...Training loss:  0.52676 ...Validation loss:  0.20358\n",
            "Iteration:  182 ...Training loss:  0.51847 ...Validation loss:  0.20036\n",
            "Iteration:  183 ...Training loss:  0.51032 ...Validation loss:  0.19719\n",
            "Iteration:  184 ...Training loss:  0.5023 ...Validation loss:  0.19406\n",
            "Iteration:  185 ...Training loss:  0.49441 ...Validation loss:  0.19098\n",
            "Iteration:  186 ...Training loss:  0.48665 ...Validation loss:  0.18795\n",
            "Iteration:  187 ...Training loss:  0.47903 ...Validation loss:  0.18496\n",
            "Iteration:  188 ...Training loss:  0.47142 ...Validation loss:  0.18202\n",
            "Iteration:  189 ...Training loss:  0.4639 ...Validation loss:  0.17912\n",
            "Iteration:  190 ...Training loss:  0.4565 ...Validation loss:  0.17626\n",
            "Iteration:  191 ...Training loss:  0.44921 ...Validation loss:  0.17345\n",
            "Iteration:  192 ...Training loss:  0.44205 ...Validation loss:  0.17068\n",
            "Iteration:  193 ...Training loss:  0.43499 ...Validation loss:  0.16795\n",
            "Iteration:  194 ...Training loss:  0.42805 ...Validation loss:  0.16526\n",
            "Iteration:  195 ...Training loss:  0.42122 ...Validation loss:  0.16261\n",
            "Iteration:  196 ...Training loss:  0.4145 ...Validation loss:  0.16\n",
            "Iteration:  197 ...Training loss:  0.40788 ...Validation loss:  0.15742\n",
            "Iteration:  198 ...Training loss:  0.40136 ...Validation loss:  0.15489\n",
            "Iteration:  199 ...Training loss:  0.39495 ...Validation loss:  0.15239\n",
            "Iteration:  200 ...Training loss:  0.38864 ...Validation loss:  0.14993\n",
            "Iteration:  201 ...Training loss:  0.38242 ...Validation loss:  0.1475\n",
            "Iteration:  202 ...Training loss:  0.3763 ...Validation loss:  0.14511\n",
            "Iteration:  203 ...Training loss:  0.37027 ...Validation loss:  0.14276\n",
            "Iteration:  204 ...Training loss:  0.36433 ...Validation loss:  0.14044\n",
            "Iteration:  205 ...Training loss:  0.35849 ...Validation loss:  0.13815\n",
            "Iteration:  206 ...Training loss:  0.35273 ...Validation loss:  0.1359\n",
            "Iteration:  207 ...Training loss:  0.34706 ...Validation loss:  0.13368\n",
            "Iteration:  208 ...Training loss:  0.34147 ...Validation loss:  0.1315\n",
            "Iteration:  209 ...Training loss:  0.33597 ...Validation loss:  0.12934\n",
            "Iteration:  210 ...Training loss:  0.33055 ...Validation loss:  0.12722\n",
            "Iteration:  211 ...Training loss:  0.32522 ...Validation loss:  0.12513\n",
            "Iteration:  212 ...Training loss:  0.31996 ...Validation loss:  0.12307\n",
            "Iteration:  213 ...Training loss:  0.31479 ...Validation loss:  0.12104\n",
            "Iteration:  214 ...Training loss:  0.30969 ...Validation loss:  0.11904\n",
            "Iteration:  215 ...Training loss:  0.30467 ...Validation loss:  0.11707\n",
            "Iteration:  216 ...Training loss:  0.29972 ...Validation loss:  0.11513\n",
            "Iteration:  217 ...Training loss:  0.29485 ...Validation loss:  0.11322\n",
            "Iteration:  218 ...Training loss:  0.29005 ...Validation loss:  0.11134\n",
            "Iteration:  219 ...Training loss:  0.28533 ...Validation loss:  0.10948\n",
            "Iteration:  220 ...Training loss:  0.28068 ...Validation loss:  0.10766\n",
            "Iteration:  221 ...Training loss:  0.27609 ...Validation loss:  0.10586\n",
            "Iteration:  222 ...Training loss:  0.27158 ...Validation loss:  0.10409\n",
            "Iteration:  223 ...Training loss:  0.26714 ...Validation loss:  0.10235\n",
            "Iteration:  224 ...Training loss:  0.26282 ...Validation loss:  0.10063\n",
            "Iteration:  225 ...Training loss:  0.25859 ...Validation loss:  0.09894\n",
            "Iteration:  226 ...Training loss:  0.25443 ...Validation loss:  0.09728\n",
            "Iteration:  227 ...Training loss:  0.25033 ...Validation loss:  0.09565\n",
            "Iteration:  228 ...Training loss:  0.2463 ...Validation loss:  0.09405\n",
            "Iteration:  229 ...Training loss:  0.24234 ...Validation loss:  0.09247\n",
            "Iteration:  230 ...Training loss:  0.23844 ...Validation loss:  0.09092\n",
            "Iteration:  231 ...Training loss:  0.2346 ...Validation loss:  0.0894\n",
            "Iteration:  232 ...Training loss:  0.23083 ...Validation loss:  0.0879\n",
            "Iteration:  233 ...Training loss:  0.22712 ...Validation loss:  0.08643\n",
            "Iteration:  234 ...Training loss:  0.22347 ...Validation loss:  0.08498\n",
            "Iteration:  235 ...Training loss:  0.21988 ...Validation loss:  0.08356\n",
            "Iteration:  236 ...Training loss:  0.21634 ...Validation loss:  0.08216\n",
            "Iteration:  237 ...Training loss:  0.21287 ...Validation loss:  0.08078\n",
            "Iteration:  238 ...Training loss:  0.20945 ...Validation loss:  0.07945\n",
            "Iteration:  239 ...Training loss:  0.20609 ...Validation loss:  0.07815\n",
            "Iteration:  240 ...Training loss:  0.20278 ...Validation loss:  0.07687\n",
            "Iteration:  241 ...Training loss:  0.19953 ...Validation loss:  0.07561\n",
            "Iteration:  242 ...Training loss:  0.19633 ...Validation loss:  0.07438\n",
            "Iteration:  243 ...Training loss:  0.19318 ...Validation loss:  0.07316\n",
            "Iteration:  244 ...Training loss:  0.19009 ...Validation loss:  0.07197\n",
            "Iteration:  245 ...Training loss:  0.18705 ...Validation loss:  0.07079\n",
            "Iteration:  246 ...Training loss:  0.18405 ...Validation loss:  0.06963\n",
            "Iteration:  247 ...Training loss:  0.18111 ...Validation loss:  0.06849\n",
            "Iteration:  248 ...Training loss:  0.17821 ...Validation loss:  0.06737\n",
            "Iteration:  249 ...Training loss:  0.17536 ...Validation loss:  0.06627\n",
            "Iteration:  250 ...Training loss:  0.17255 ...Validation loss:  0.06519\n",
            "Iteration:  251 ...Training loss:  0.16976 ...Validation loss:  0.06412\n",
            "Iteration:  252 ...Training loss:  0.16702 ...Validation loss:  0.06307\n",
            "Iteration:  253 ...Training loss:  0.16432 ...Validation loss:  0.06204\n",
            "Iteration:  254 ...Training loss:  0.16165 ...Validation loss:  0.06102\n",
            "Iteration:  255 ...Training loss:  0.15904 ...Validation loss:  0.06003\n",
            "Iteration:  256 ...Training loss:  0.15646 ...Validation loss:  0.05904\n",
            "Iteration:  257 ...Training loss:  0.15393 ...Validation loss:  0.05808\n",
            "Iteration:  258 ...Training loss:  0.15144 ...Validation loss:  0.05713\n",
            "Iteration:  259 ...Training loss:  0.14899 ...Validation loss:  0.05619\n",
            "Iteration:  260 ...Training loss:  0.14658 ...Validation loss:  0.05527\n",
            "Iteration:  261 ...Training loss:  0.14421 ...Validation loss:  0.05437\n",
            "Iteration:  262 ...Training loss:  0.14188 ...Validation loss:  0.05348\n",
            "Iteration:  263 ...Training loss:  0.13959 ...Validation loss:  0.05261\n",
            "Iteration:  264 ...Training loss:  0.13733 ...Validation loss:  0.05175\n",
            "Iteration:  265 ...Training loss:  0.1351 ...Validation loss:  0.0509\n",
            "Iteration:  266 ...Training loss:  0.13291 ...Validation loss:  0.05007\n",
            "Iteration:  267 ...Training loss:  0.13075 ...Validation loss:  0.04925\n",
            "Iteration:  268 ...Training loss:  0.12863 ...Validation loss:  0.04845\n",
            "Iteration:  269 ...Training loss:  0.12654 ...Validation loss:  0.04766\n",
            "Iteration:  270 ...Training loss:  0.12449 ...Validation loss:  0.04688\n",
            "Iteration:  271 ...Training loss:  0.12247 ...Validation loss:  0.04611\n",
            "Iteration:  272 ...Training loss:  0.12048 ...Validation loss:  0.04536\n",
            "Iteration:  273 ...Training loss:  0.11853 ...Validation loss:  0.04462\n",
            "Iteration:  274 ...Training loss:  0.11661 ...Validation loss:  0.04389\n",
            "Iteration:  275 ...Training loss:  0.11472 ...Validation loss:  0.04318\n",
            "Iteration:  276 ...Training loss:  0.11286 ...Validation loss:  0.04248\n",
            "Iteration:  277 ...Training loss:  0.11103 ...Validation loss:  0.04178\n",
            "Iteration:  278 ...Training loss:  0.10923 ...Validation loss:  0.0411\n",
            "Iteration:  279 ...Training loss:  0.10747 ...Validation loss:  0.04044\n",
            "Iteration:  280 ...Training loss:  0.10573 ...Validation loss:  0.03978\n",
            "Iteration:  281 ...Training loss:  0.10402 ...Validation loss:  0.03913\n",
            "Iteration:  282 ...Training loss:  0.10233 ...Validation loss:  0.0385\n",
            "Iteration:  283 ...Training loss:  0.10068 ...Validation loss:  0.03787\n",
            "Iteration:  284 ...Training loss:  0.09905 ...Validation loss:  0.03726\n",
            "Iteration:  285 ...Training loss:  0.09746 ...Validation loss:  0.03666\n",
            "Iteration:  286 ...Training loss:  0.09588 ...Validation loss:  0.03606\n",
            "Iteration:  287 ...Training loss:  0.09434 ...Validation loss:  0.03549\n",
            "Iteration:  288 ...Training loss:  0.09282 ...Validation loss:  0.03494\n",
            "Iteration:  289 ...Training loss:  0.09133 ...Validation loss:  0.03439\n",
            "Iteration:  290 ...Training loss:  0.08986 ...Validation loss:  0.03385\n",
            "Iteration:  291 ...Training loss:  0.08841 ...Validation loss:  0.03332\n",
            "Iteration:  292 ...Training loss:  0.08699 ...Validation loss:  0.0328\n",
            "Iteration:  293 ...Training loss:  0.08558 ...Validation loss:  0.03228\n",
            "Iteration:  294 ...Training loss:  0.0842 ...Validation loss:  0.03178\n",
            "Iteration:  295 ...Training loss:  0.08283 ...Validation loss:  0.03128\n",
            "Iteration:  296 ...Training loss:  0.08149 ...Validation loss:  0.03079\n",
            "Iteration:  297 ...Training loss:  0.08017 ...Validation loss:  0.0303\n",
            "Iteration:  298 ...Training loss:  0.07888 ...Validation loss:  0.02983\n",
            "Iteration:  299 ...Training loss:  0.0776 ...Validation loss:  0.02936\n",
            "Iteration:  300 ...Training loss:  0.07635 ...Validation loss:  0.0289\n",
            "Iteration:  301 ...Training loss:  0.07511 ...Validation loss:  0.02845\n",
            "Iteration:  302 ...Training loss:  0.0739 ...Validation loss:  0.028\n",
            "Iteration:  303 ...Training loss:  0.07271 ...Validation loss:  0.02757\n",
            "Iteration:  304 ...Training loss:  0.07153 ...Validation loss:  0.02713\n",
            "Iteration:  305 ...Training loss:  0.07038 ...Validation loss:  0.02671\n",
            "Iteration:  306 ...Training loss:  0.06924 ...Validation loss:  0.02629\n",
            "Iteration:  307 ...Training loss:  0.06813 ...Validation loss:  0.02588\n",
            "Iteration:  308 ...Training loss:  0.06703 ...Validation loss:  0.02548\n",
            "Iteration:  309 ...Training loss:  0.06595 ...Validation loss:  0.02508\n",
            "Iteration:  310 ...Training loss:  0.06489 ...Validation loss:  0.02469\n",
            "Iteration:  311 ...Training loss:  0.06384 ...Validation loss:  0.0243\n",
            "Iteration:  312 ...Training loss:  0.06282 ...Validation loss:  0.02392\n",
            "Iteration:  313 ...Training loss:  0.06181 ...Validation loss:  0.02355\n",
            "Iteration:  314 ...Training loss:  0.06081 ...Validation loss:  0.02318\n",
            "Iteration:  315 ...Training loss:  0.05984 ...Validation loss:  0.02282\n",
            "Iteration:  316 ...Training loss:  0.05887 ...Validation loss:  0.02246\n",
            "Iteration:  317 ...Training loss:  0.05793 ...Validation loss:  0.02211\n",
            "Iteration:  318 ...Training loss:  0.057 ...Validation loss:  0.02176\n",
            "Iteration:  319 ...Training loss:  0.05608 ...Validation loss:  0.02142\n",
            "Iteration:  320 ...Training loss:  0.05519 ...Validation loss:  0.02109\n",
            "Iteration:  321 ...Training loss:  0.0543 ...Validation loss:  0.02076\n",
            "Iteration:  322 ...Training loss:  0.05343 ...Validation loss:  0.02044\n",
            "Iteration:  323 ...Training loss:  0.05257 ...Validation loss:  0.02012\n",
            "Iteration:  324 ...Training loss:  0.05173 ...Validation loss:  0.0198\n",
            "Iteration:  325 ...Training loss:  0.0509 ...Validation loss:  0.01949\n",
            "Iteration:  326 ...Training loss:  0.05009 ...Validation loss:  0.01919\n",
            "Iteration:  327 ...Training loss:  0.04928 ...Validation loss:  0.01889\n",
            "Iteration:  328 ...Training loss:  0.04849 ...Validation loss:  0.01859\n",
            "Iteration:  329 ...Training loss:  0.04772 ...Validation loss:  0.0183\n",
            "Iteration:  330 ...Training loss:  0.04695 ...Validation loss:  0.01802\n",
            "Iteration:  331 ...Training loss:  0.0462 ...Validation loss:  0.01773\n",
            "Iteration:  332 ...Training loss:  0.04546 ...Validation loss:  0.01746\n",
            "Iteration:  333 ...Training loss:  0.04473 ...Validation loss:  0.01718\n",
            "Iteration:  334 ...Training loss:  0.04401 ...Validation loss:  0.01691\n",
            "Iteration:  335 ...Training loss:  0.04331 ...Validation loss:  0.01665\n",
            "Iteration:  336 ...Training loss:  0.04261 ...Validation loss:  0.01639\n",
            "Iteration:  337 ...Training loss:  0.04193 ...Validation loss:  0.01613\n",
            "Iteration:  338 ...Training loss:  0.04126 ...Validation loss:  0.01588\n",
            "Iteration:  339 ...Training loss:  0.0406 ...Validation loss:  0.01563\n",
            "Iteration:  340 ...Training loss:  0.03994 ...Validation loss:  0.01538\n",
            "Iteration:  341 ...Training loss:  0.0393 ...Validation loss:  0.01514\n",
            "Iteration:  342 ...Training loss:  0.03867 ...Validation loss:  0.0149\n",
            "Iteration:  343 ...Training loss:  0.03805 ...Validation loss:  0.01467\n",
            "Iteration:  344 ...Training loss:  0.03744 ...Validation loss:  0.01444\n",
            "Iteration:  345 ...Training loss:  0.03684 ...Validation loss:  0.01421\n",
            "Iteration:  346 ...Training loss:  0.03624 ...Validation loss:  0.01399\n",
            "Iteration:  347 ...Training loss:  0.03566 ...Validation loss:  0.01377\n",
            "Iteration:  348 ...Training loss:  0.03509 ...Validation loss:  0.01355\n",
            "Iteration:  349 ...Training loss:  0.03452 ...Validation loss:  0.01334\n",
            "Iteration:  350 ...Training loss:  0.03397 ...Validation loss:  0.01312\n",
            "Iteration:  351 ...Training loss:  0.03342 ...Validation loss:  0.01292\n",
            "Iteration:  352 ...Training loss:  0.03288 ...Validation loss:  0.01271\n",
            "Iteration:  353 ...Training loss:  0.03235 ...Validation loss:  0.01251\n",
            "Iteration:  354 ...Training loss:  0.03183 ...Validation loss:  0.01231\n",
            "Iteration:  355 ...Training loss:  0.03132 ...Validation loss:  0.01212\n",
            "Iteration:  356 ...Training loss:  0.03081 ...Validation loss:  0.01193\n",
            "Iteration:  357 ...Training loss:  0.03032 ...Validation loss:  0.01174\n",
            "Iteration:  358 ...Training loss:  0.02983 ...Validation loss:  0.01155\n",
            "Iteration:  359 ...Training loss:  0.02936 ...Validation loss:  0.01137\n",
            "Iteration:  360 ...Training loss:  0.02889 ...Validation loss:  0.01119\n",
            "Iteration:  361 ...Training loss:  0.02842 ...Validation loss:  0.01101\n",
            "Iteration:  362 ...Training loss:  0.02797 ...Validation loss:  0.01084\n",
            "Iteration:  363 ...Training loss:  0.02752 ...Validation loss:  0.01066\n",
            "Iteration:  364 ...Training loss:  0.02708 ...Validation loss:  0.01049\n",
            "Iteration:  365 ...Training loss:  0.02665 ...Validation loss:  0.01033\n",
            "Iteration:  366 ...Training loss:  0.02622 ...Validation loss:  0.01016\n",
            "Iteration:  367 ...Training loss:  0.0258 ...Validation loss:  0.01\n",
            "Iteration:  368 ...Training loss:  0.02539 ...Validation loss:  0.00985\n",
            "Iteration:  369 ...Training loss:  0.02498 ...Validation loss:  0.00969\n",
            "Iteration:  370 ...Training loss:  0.02458 ...Validation loss:  0.00954\n",
            "Iteration:  371 ...Training loss:  0.02419 ...Validation loss:  0.00938\n",
            "Iteration:  372 ...Training loss:  0.02381 ...Validation loss:  0.00924\n",
            "Iteration:  373 ...Training loss:  0.02343 ...Validation loss:  0.00909\n",
            "Iteration:  374 ...Training loss:  0.02305 ...Validation loss:  0.00894\n",
            "Iteration:  375 ...Training loss:  0.02268 ...Validation loss:  0.0088\n",
            "Iteration:  376 ...Training loss:  0.02232 ...Validation loss:  0.00866\n",
            "Iteration:  377 ...Training loss:  0.02196 ...Validation loss:  0.00853\n",
            "Iteration:  378 ...Training loss:  0.02161 ...Validation loss:  0.00839\n",
            "Iteration:  379 ...Training loss:  0.02127 ...Validation loss:  0.00826\n",
            "Iteration:  380 ...Training loss:  0.02093 ...Validation loss:  0.00813\n",
            "Iteration:  381 ...Training loss:  0.0206 ...Validation loss:  0.008\n",
            "Iteration:  382 ...Training loss:  0.02027 ...Validation loss:  0.00787\n",
            "Iteration:  383 ...Training loss:  0.01994 ...Validation loss:  0.00775\n",
            "Iteration:  384 ...Training loss:  0.01963 ...Validation loss:  0.00762\n",
            "Iteration:  385 ...Training loss:  0.01931 ...Validation loss:  0.0075\n",
            "Iteration:  386 ...Training loss:  0.01901 ...Validation loss:  0.00738\n",
            "Iteration:  387 ...Training loss:  0.0187 ...Validation loss:  0.00727\n",
            "Iteration:  388 ...Training loss:  0.0184 ...Validation loss:  0.00715\n",
            "Iteration:  389 ...Training loss:  0.01811 ...Validation loss:  0.00704\n",
            "Iteration:  390 ...Training loss:  0.01782 ...Validation loss:  0.00693\n",
            "Iteration:  391 ...Training loss:  0.01754 ...Validation loss:  0.00682\n",
            "Iteration:  392 ...Training loss:  0.01726 ...Validation loss:  0.00671\n",
            "Iteration:  393 ...Training loss:  0.01699 ...Validation loss:  0.0066\n",
            "Iteration:  394 ...Training loss:  0.01671 ...Validation loss:  0.0065\n",
            "Iteration:  395 ...Training loss:  0.01645 ...Validation loss:  0.00639\n",
            "Iteration:  396 ...Training loss:  0.01619 ...Validation loss:  0.00629\n",
            "Iteration:  397 ...Training loss:  0.01593 ...Validation loss:  0.00619\n",
            "Iteration:  398 ...Training loss:  0.01568 ...Validation loss:  0.00609\n",
            "Iteration:  399 ...Training loss:  0.01543 ...Validation loss:  0.006\n",
            "Iteration:  400 ...Training loss:  0.01518 ...Validation loss:  0.0059\n",
            "Iteration:  401 ...Training loss:  0.01494 ...Validation loss:  0.00581\n",
            "Iteration:  402 ...Training loss:  0.0147 ...Validation loss:  0.00571\n",
            "Iteration:  403 ...Training loss:  0.01447 ...Validation loss:  0.00562\n",
            "Iteration:  404 ...Training loss:  0.01424 ...Validation loss:  0.00553\n",
            "Iteration:  405 ...Training loss:  0.01401 ...Validation loss:  0.00545\n",
            "Iteration:  406 ...Training loss:  0.01379 ...Validation loss:  0.00536\n",
            "Iteration:  407 ...Training loss:  0.01357 ...Validation loss:  0.00527\n",
            "Iteration:  408 ...Training loss:  0.01335 ...Validation loss:  0.00519\n",
            "Iteration:  409 ...Training loss:  0.01314 ...Validation loss:  0.00511\n",
            "Iteration:  410 ...Training loss:  0.01293 ...Validation loss:  0.00502\n",
            "Iteration:  411 ...Training loss:  0.01273 ...Validation loss:  0.00494\n",
            "Iteration:  412 ...Training loss:  0.01252 ...Validation loss:  0.00487\n",
            "Iteration:  413 ...Training loss:  0.01232 ...Validation loss:  0.00479\n",
            "Iteration:  414 ...Training loss:  0.01213 ...Validation loss:  0.00471\n",
            "Iteration:  415 ...Training loss:  0.01193 ...Validation loss:  0.00464\n",
            "Iteration:  416 ...Training loss:  0.01174 ...Validation loss:  0.00456\n",
            "Iteration:  417 ...Training loss:  0.01156 ...Validation loss:  0.00449\n",
            "Iteration:  418 ...Training loss:  0.01137 ...Validation loss:  0.00442\n",
            "Iteration:  419 ...Training loss:  0.01119 ...Validation loss:  0.00435\n",
            "Iteration:  420 ...Training loss:  0.01101 ...Validation loss:  0.00428\n",
            "Iteration:  421 ...Training loss:  0.01084 ...Validation loss:  0.00421\n",
            "Iteration:  422 ...Training loss:  0.01066 ...Validation loss:  0.00414\n",
            "Iteration:  423 ...Training loss:  0.01049 ...Validation loss:  0.00407\n",
            "Iteration:  424 ...Training loss:  0.01033 ...Validation loss:  0.00401\n",
            "Iteration:  425 ...Training loss:  0.01016 ...Validation loss:  0.00394\n",
            "Iteration:  426 ...Training loss:  0.01 ...Validation loss:  0.00388\n",
            "Iteration:  427 ...Training loss:  0.00984 ...Validation loss:  0.00382\n",
            "Iteration:  428 ...Training loss:  0.00969 ...Validation loss:  0.00376\n",
            "Iteration:  429 ...Training loss:  0.00953 ...Validation loss:  0.0037\n",
            "Iteration:  430 ...Training loss:  0.00938 ...Validation loss:  0.00364\n",
            "Iteration:  431 ...Training loss:  0.00923 ...Validation loss:  0.00358\n",
            "Iteration:  432 ...Training loss:  0.00909 ...Validation loss:  0.00352\n",
            "Iteration:  433 ...Training loss:  0.00894 ...Validation loss:  0.00346\n",
            "Iteration:  434 ...Training loss:  0.0088 ...Validation loss:  0.00341\n",
            "Iteration:  435 ...Training loss:  0.00866 ...Validation loss:  0.00335\n",
            "Iteration:  436 ...Training loss:  0.00852 ...Validation loss:  0.0033\n",
            "Iteration:  437 ...Training loss:  0.00839 ...Validation loss:  0.00325\n",
            "Iteration:  438 ...Training loss:  0.00825 ...Validation loss:  0.0032\n",
            "Iteration:  439 ...Training loss:  0.00812 ...Validation loss:  0.00314\n",
            "Iteration:  440 ...Training loss:  0.00799 ...Validation loss:  0.00309\n",
            "Iteration:  441 ...Training loss:  0.00786 ...Validation loss:  0.00304\n",
            "Iteration:  442 ...Training loss:  0.00773 ...Validation loss:  0.00299\n",
            "Iteration:  443 ...Training loss:  0.00761 ...Validation loss:  0.00295\n",
            "Iteration:  444 ...Training loss:  0.00749 ...Validation loss:  0.0029\n",
            "Iteration:  445 ...Training loss:  0.00737 ...Validation loss:  0.00285\n",
            "Iteration:  446 ...Training loss:  0.00725 ...Validation loss:  0.00281\n",
            "Iteration:  447 ...Training loss:  0.00713 ...Validation loss:  0.00276\n",
            "Iteration:  448 ...Training loss:  0.00701 ...Validation loss:  0.00272\n",
            "Iteration:  449 ...Training loss:  0.0069 ...Validation loss:  0.00267\n",
            "Iteration:  450 ...Training loss:  0.00679 ...Validation loss:  0.00263\n",
            "Iteration:  451 ...Training loss:  0.00668 ...Validation loss:  0.00259\n",
            "Iteration:  452 ...Training loss:  0.00657 ...Validation loss:  0.00255\n",
            "Iteration:  453 ...Training loss:  0.00647 ...Validation loss:  0.0025\n",
            "Iteration:  454 ...Training loss:  0.00636 ...Validation loss:  0.00246\n",
            "Iteration:  455 ...Training loss:  0.00626 ...Validation loss:  0.00242\n",
            "Iteration:  456 ...Training loss:  0.00616 ...Validation loss:  0.00238\n",
            "Iteration:  457 ...Training loss:  0.00606 ...Validation loss:  0.00235\n",
            "Iteration:  458 ...Training loss:  0.00596 ...Validation loss:  0.00231\n",
            "Iteration:  459 ...Training loss:  0.00586 ...Validation loss:  0.00227\n",
            "Iteration:  460 ...Training loss:  0.00577 ...Validation loss:  0.00223\n",
            "Iteration:  461 ...Training loss:  0.00567 ...Validation loss:  0.0022\n",
            "Iteration:  462 ...Training loss:  0.00558 ...Validation loss:  0.00216\n",
            "Iteration:  463 ...Training loss:  0.00549 ...Validation loss:  0.00213\n",
            "Iteration:  464 ...Training loss:  0.0054 ...Validation loss:  0.00209\n",
            "Iteration:  465 ...Training loss:  0.00531 ...Validation loss:  0.00206\n",
            "Iteration:  466 ...Training loss:  0.00523 ...Validation loss:  0.00203\n",
            "Iteration:  467 ...Training loss:  0.00514 ...Validation loss:  0.00199\n",
            "Iteration:  468 ...Training loss:  0.00506 ...Validation loss:  0.00196\n",
            "Iteration:  469 ...Training loss:  0.00498 ...Validation loss:  0.00193\n",
            "Iteration:  470 ...Training loss:  0.0049 ...Validation loss:  0.0019\n",
            "Iteration:  471 ...Training loss:  0.00482 ...Validation loss:  0.00187\n",
            "Iteration:  472 ...Training loss:  0.00474 ...Validation loss:  0.00184\n",
            "Iteration:  473 ...Training loss:  0.00466 ...Validation loss:  0.00181\n",
            "Iteration:  474 ...Training loss:  0.00459 ...Validation loss:  0.00178\n",
            "Iteration:  475 ...Training loss:  0.00451 ...Validation loss:  0.00175\n",
            "Iteration:  476 ...Training loss:  0.00444 ...Validation loss:  0.00172\n",
            "Iteration:  477 ...Training loss:  0.00437 ...Validation loss:  0.00169\n",
            "Iteration:  478 ...Training loss:  0.0043 ...Validation loss:  0.00167\n",
            "Iteration:  479 ...Training loss:  0.00423 ...Validation loss:  0.00164\n",
            "Iteration:  480 ...Training loss:  0.00416 ...Validation loss:  0.00161\n",
            "Iteration:  481 ...Training loss:  0.00409 ...Validation loss:  0.00159\n",
            "Iteration:  482 ...Training loss:  0.00402 ...Validation loss:  0.00156\n",
            "Iteration:  483 ...Training loss:  0.00396 ...Validation loss:  0.00153\n",
            "Iteration:  484 ...Training loss:  0.0039 ...Validation loss:  0.00151\n",
            "Iteration:  485 ...Training loss:  0.00383 ...Validation loss:  0.00149\n",
            "Iteration:  486 ...Training loss:  0.00377 ...Validation loss:  0.00146\n",
            "Iteration:  487 ...Training loss:  0.00371 ...Validation loss:  0.00144\n",
            "Iteration:  488 ...Training loss:  0.00365 ...Validation loss:  0.00141\n",
            "Iteration:  489 ...Training loss:  0.00359 ...Validation loss:  0.00139\n",
            "Iteration:  490 ...Training loss:  0.00353 ...Validation loss:  0.00137\n",
            "Iteration:  491 ...Training loss:  0.00347 ...Validation loss:  0.00135\n",
            "Iteration:  492 ...Training loss:  0.00342 ...Validation loss:  0.00132\n",
            "Iteration:  493 ...Training loss:  0.00336 ...Validation loss:  0.0013\n",
            "Iteration:  494 ...Training loss:  0.00331 ...Validation loss:  0.00128\n",
            "Iteration:  495 ...Training loss:  0.00325 ...Validation loss:  0.00126\n",
            "Iteration:  496 ...Training loss:  0.0032 ...Validation loss:  0.00124\n",
            "Iteration:  497 ...Training loss:  0.00315 ...Validation loss:  0.00122\n",
            "Iteration:  498 ...Training loss:  0.0031 ...Validation loss:  0.0012\n",
            "Iteration:  499 ...Training loss:  0.00305 ...Validation loss:  0.00118\n",
            "Iteration:  500 ...Training loss:  0.003 ...Validation loss:  0.00116\n",
            "Iteration:  501 ...Training loss:  0.00295 ...Validation loss:  0.00114\n",
            "Iteration:  502 ...Training loss:  0.0029 ...Validation loss:  0.00112\n",
            "Iteration:  503 ...Training loss:  0.00285 ...Validation loss:  0.00111\n",
            "Iteration:  504 ...Training loss:  0.00281 ...Validation loss:  0.00109\n",
            "Iteration:  505 ...Training loss:  0.00276 ...Validation loss:  0.00107\n",
            "Iteration:  506 ...Training loss:  0.00272 ...Validation loss:  0.00105\n",
            "Iteration:  507 ...Training loss:  0.00267 ...Validation loss:  0.00104\n",
            "Iteration:  508 ...Training loss:  0.00263 ...Validation loss:  0.00102\n",
            "Iteration:  509 ...Training loss:  0.00259 ...Validation loss:  0.001\n",
            "Iteration:  510 ...Training loss:  0.00254 ...Validation loss:  0.00099\n",
            "Iteration:  511 ...Training loss:  0.0025 ...Validation loss:  0.00097\n",
            "Iteration:  512 ...Training loss:  0.00246 ...Validation loss:  0.00095\n",
            "Iteration:  513 ...Training loss:  0.00242 ...Validation loss:  0.00094\n",
            "Iteration:  514 ...Training loss:  0.00238 ...Validation loss:  0.00092\n",
            "Iteration:  515 ...Training loss:  0.00234 ...Validation loss:  0.00091\n",
            "Iteration:  516 ...Training loss:  0.0023 ...Validation loss:  0.00089\n",
            "Iteration:  517 ...Training loss:  0.00227 ...Validation loss:  0.00088\n",
            "Iteration:  518 ...Training loss:  0.00223 ...Validation loss:  0.00086\n",
            "Iteration:  519 ...Training loss:  0.00219 ...Validation loss:  0.00085\n",
            "Iteration:  520 ...Training loss:  0.00216 ...Validation loss:  0.00084\n",
            "Iteration:  521 ...Training loss:  0.00212 ...Validation loss:  0.00082\n",
            "Iteration:  522 ...Training loss:  0.00209 ...Validation loss:  0.00081\n",
            "Iteration:  523 ...Training loss:  0.00205 ...Validation loss:  0.0008\n",
            "Iteration:  524 ...Training loss:  0.00202 ...Validation loss:  0.00078\n",
            "Iteration:  525 ...Training loss:  0.00199 ...Validation loss:  0.00077\n",
            "Iteration:  526 ...Training loss:  0.00196 ...Validation loss:  0.00076\n",
            "Iteration:  527 ...Training loss:  0.00192 ...Validation loss:  0.00075\n",
            "Iteration:  528 ...Training loss:  0.00189 ...Validation loss:  0.00073\n",
            "Iteration:  529 ...Training loss:  0.00186 ...Validation loss:  0.00072\n",
            "Iteration:  530 ...Training loss:  0.00183 ...Validation loss:  0.00071\n",
            "Iteration:  531 ...Training loss:  0.0018 ...Validation loss:  0.0007\n",
            "Iteration:  532 ...Training loss:  0.00177 ...Validation loss:  0.00069\n",
            "Iteration:  533 ...Training loss:  0.00174 ...Validation loss:  0.00068\n",
            "Iteration:  534 ...Training loss:  0.00171 ...Validation loss:  0.00066\n",
            "Iteration:  535 ...Training loss:  0.00169 ...Validation loss:  0.00065\n",
            "Iteration:  536 ...Training loss:  0.00166 ...Validation loss:  0.00064\n",
            "Iteration:  537 ...Training loss:  0.00163 ...Validation loss:  0.00063\n",
            "Iteration:  538 ...Training loss:  0.00161 ...Validation loss:  0.00062\n",
            "Iteration:  539 ...Training loss:  0.00158 ...Validation loss:  0.00061\n",
            "Iteration:  540 ...Training loss:  0.00155 ...Validation loss:  0.0006\n",
            "Iteration:  541 ...Training loss:  0.00153 ...Validation loss:  0.00059\n",
            "Iteration:  542 ...Training loss:  0.0015 ...Validation loss:  0.00058\n",
            "Iteration:  543 ...Training loss:  0.00148 ...Validation loss:  0.00057\n",
            "Iteration:  544 ...Training loss:  0.00145 ...Validation loss:  0.00056\n",
            "Iteration:  545 ...Training loss:  0.00143 ...Validation loss:  0.00055\n",
            "Iteration:  546 ...Training loss:  0.00141 ...Validation loss:  0.00055\n",
            "Iteration:  547 ...Training loss:  0.00138 ...Validation loss:  0.00054\n",
            "Iteration:  548 ...Training loss:  0.00136 ...Validation loss:  0.00053\n",
            "Iteration:  549 ...Training loss:  0.00134 ...Validation loss:  0.00052\n",
            "Iteration:  550 ...Training loss:  0.00132 ...Validation loss:  0.00051\n",
            "Iteration:  551 ...Training loss:  0.0013 ...Validation loss:  0.0005\n",
            "Iteration:  552 ...Training loss:  0.00128 ...Validation loss:  0.00049\n",
            "Iteration:  553 ...Training loss:  0.00125 ...Validation loss:  0.00049\n",
            "Iteration:  554 ...Training loss:  0.00123 ...Validation loss:  0.00048\n",
            "Iteration:  555 ...Training loss:  0.00121 ...Validation loss:  0.00047\n",
            "Iteration:  556 ...Training loss:  0.00119 ...Validation loss:  0.00046\n",
            "Iteration:  557 ...Training loss:  0.00117 ...Validation loss:  0.00046\n",
            "Iteration:  558 ...Training loss:  0.00116 ...Validation loss:  0.00045\n",
            "Iteration:  559 ...Training loss:  0.00114 ...Validation loss:  0.00044\n",
            "Iteration:  560 ...Training loss:  0.00112 ...Validation loss:  0.00043\n",
            "Iteration:  561 ...Training loss:  0.0011 ...Validation loss:  0.00043\n",
            "Iteration:  562 ...Training loss:  0.00108 ...Validation loss:  0.00042\n",
            "Iteration:  563 ...Training loss:  0.00106 ...Validation loss:  0.00041\n",
            "Iteration:  564 ...Training loss:  0.00105 ...Validation loss:  0.00041\n",
            "Iteration:  565 ...Training loss:  0.00103 ...Validation loss:  0.0004\n",
            "Iteration:  566 ...Training loss:  0.00101 ...Validation loss:  0.00039\n",
            "Iteration:  567 ...Training loss:  0.001 ...Validation loss:  0.00039\n",
            "Iteration:  568 ...Training loss:  0.00098 ...Validation loss:  0.00038\n",
            "Iteration:  569 ...Training loss:  0.00096 ...Validation loss:  0.00037\n",
            "Iteration:  570 ...Training loss:  0.00095 ...Validation loss:  0.00037\n",
            "Iteration:  571 ...Training loss:  0.00093 ...Validation loss:  0.00036\n",
            "Iteration:  572 ...Training loss:  0.00092 ...Validation loss:  0.00036\n",
            "Iteration:  573 ...Training loss:  0.0009 ...Validation loss:  0.00035\n",
            "Iteration:  574 ...Training loss:  0.00089 ...Validation loss:  0.00034\n",
            "Iteration:  575 ...Training loss:  0.00087 ...Validation loss:  0.00034\n",
            "Iteration:  576 ...Training loss:  0.00086 ...Validation loss:  0.00033\n",
            "Iteration:  577 ...Training loss:  0.00084 ...Validation loss:  0.00033\n",
            "Iteration:  578 ...Training loss:  0.00083 ...Validation loss:  0.00032\n",
            "Iteration:  579 ...Training loss:  0.00082 ...Validation loss:  0.00032\n",
            "Iteration:  580 ...Training loss:  0.0008 ...Validation loss:  0.00031\n",
            "Iteration:  581 ...Training loss:  0.00079 ...Validation loss:  0.00031\n",
            "Iteration:  582 ...Training loss:  0.00078 ...Validation loss:  0.0003\n",
            "Iteration:  583 ...Training loss:  0.00076 ...Validation loss:  0.0003\n",
            "Iteration:  584 ...Training loss:  0.00075 ...Validation loss:  0.00029\n",
            "Iteration:  585 ...Training loss:  0.00074 ...Validation loss:  0.00029\n",
            "Iteration:  586 ...Training loss:  0.00073 ...Validation loss:  0.00028\n",
            "Iteration:  587 ...Training loss:  0.00072 ...Validation loss:  0.00028\n",
            "Iteration:  588 ...Training loss:  0.0007 ...Validation loss:  0.00027\n",
            "Iteration:  589 ...Training loss:  0.00069 ...Validation loss:  0.00027\n",
            "Iteration:  590 ...Training loss:  0.00068 ...Validation loss:  0.00026\n",
            "Iteration:  591 ...Training loss:  0.00067 ...Validation loss:  0.00026\n",
            "Iteration:  592 ...Training loss:  0.00066 ...Validation loss:  0.00026\n",
            "Iteration:  593 ...Training loss:  0.00065 ...Validation loss:  0.00025\n",
            "Iteration:  594 ...Training loss:  0.00064 ...Validation loss:  0.00025\n",
            "Iteration:  595 ...Training loss:  0.00063 ...Validation loss:  0.00024\n",
            "Iteration:  596 ...Training loss:  0.00062 ...Validation loss:  0.00024\n",
            "Iteration:  597 ...Training loss:  0.00061 ...Validation loss:  0.00024\n",
            "Iteration:  598 ...Training loss:  0.0006 ...Validation loss:  0.00023\n",
            "Iteration:  599 ...Training loss:  0.00059 ...Validation loss:  0.00023\n",
            "Iteration:  600 ...Training loss:  0.00058 ...Validation loss:  0.00022\n",
            "Iteration:  601 ...Training loss:  0.00057 ...Validation loss:  0.00022\n",
            "Iteration:  602 ...Training loss:  0.00056 ...Validation loss:  0.00022\n",
            "Iteration:  603 ...Training loss:  0.00055 ...Validation loss:  0.00021\n",
            "Iteration:  604 ...Training loss:  0.00054 ...Validation loss:  0.00021\n",
            "Iteration:  605 ...Training loss:  0.00053 ...Validation loss:  0.00021\n",
            "Iteration:  606 ...Training loss:  0.00052 ...Validation loss:  0.0002\n",
            "Iteration:  607 ...Training loss:  0.00051 ...Validation loss:  0.0002\n",
            "Iteration:  608 ...Training loss:  0.00051 ...Validation loss:  0.0002\n",
            "Iteration:  609 ...Training loss:  0.0005 ...Validation loss:  0.00019\n",
            "Iteration:  610 ...Training loss:  0.00049 ...Validation loss:  0.00019\n",
            "Iteration:  611 ...Training loss:  0.00048 ...Validation loss:  0.00019\n",
            "Iteration:  612 ...Training loss:  0.00047 ...Validation loss:  0.00018\n",
            "Iteration:  613 ...Training loss:  0.00047 ...Validation loss:  0.00018\n",
            "Iteration:  614 ...Training loss:  0.00046 ...Validation loss:  0.00018\n",
            "Iteration:  615 ...Training loss:  0.00045 ...Validation loss:  0.00018\n",
            "Iteration:  616 ...Training loss:  0.00044 ...Validation loss:  0.00017\n",
            "Iteration:  617 ...Training loss:  0.00044 ...Validation loss:  0.00017\n",
            "Iteration:  618 ...Training loss:  0.00043 ...Validation loss:  0.00017\n",
            "Iteration:  619 ...Training loss:  0.00042 ...Validation loss:  0.00016\n",
            "Iteration:  620 ...Training loss:  0.00042 ...Validation loss:  0.00016\n",
            "Iteration:  621 ...Training loss:  0.00041 ...Validation loss:  0.00016\n",
            "Iteration:  622 ...Training loss:  0.0004 ...Validation loss:  0.00016\n",
            "Iteration:  623 ...Training loss:  0.0004 ...Validation loss:  0.00015\n",
            "Iteration:  624 ...Training loss:  0.00039 ...Validation loss:  0.00015\n",
            "Iteration:  625 ...Training loss:  0.00038 ...Validation loss:  0.00015\n",
            "Iteration:  626 ...Training loss:  0.00038 ...Validation loss:  0.00015\n",
            "Iteration:  627 ...Training loss:  0.00037 ...Validation loss:  0.00014\n",
            "Iteration:  628 ...Training loss:  0.00036 ...Validation loss:  0.00014\n",
            "Iteration:  629 ...Training loss:  0.00036 ...Validation loss:  0.00014\n",
            "Iteration:  630 ...Training loss:  0.00035 ...Validation loss:  0.00014\n",
            "Iteration:  631 ...Training loss:  0.00035 ...Validation loss:  0.00013\n",
            "Iteration:  632 ...Training loss:  0.00034 ...Validation loss:  0.00013\n",
            "Iteration:  633 ...Training loss:  0.00034 ...Validation loss:  0.00013\n",
            "Iteration:  634 ...Training loss:  0.00033 ...Validation loss:  0.00013\n",
            "Iteration:  635 ...Training loss:  0.00032 ...Validation loss:  0.00013\n",
            "Iteration:  636 ...Training loss:  0.00032 ...Validation loss:  0.00012\n",
            "Iteration:  637 ...Training loss:  0.00031 ...Validation loss:  0.00012\n",
            "Iteration:  638 ...Training loss:  0.00031 ...Validation loss:  0.00012\n",
            "Iteration:  639 ...Training loss:  0.0003 ...Validation loss:  0.00012\n",
            "Iteration:  640 ...Training loss:  0.0003 ...Validation loss:  0.00012\n",
            "Iteration:  641 ...Training loss:  0.00029 ...Validation loss:  0.00011\n",
            "Iteration:  642 ...Training loss:  0.00029 ...Validation loss:  0.00011\n",
            "Iteration:  643 ...Training loss:  0.00028 ...Validation loss:  0.00011\n",
            "Iteration:  644 ...Training loss:  0.00028 ...Validation loss:  0.00011\n",
            "Iteration:  645 ...Training loss:  0.00027 ...Validation loss:  0.00011\n",
            "Iteration:  646 ...Training loss:  0.00027 ...Validation loss:  0.0001\n",
            "Iteration:  647 ...Training loss:  0.00027 ...Validation loss:  0.0001\n",
            "Iteration:  648 ...Training loss:  0.00026 ...Validation loss:  0.0001\n",
            "Iteration:  649 ...Training loss:  0.00026 ...Validation loss:  0.0001\n",
            "Iteration:  650 ...Training loss:  0.00025 ...Validation loss:  0.0001\n",
            "Iteration:  651 ...Training loss:  0.00025 ...Validation loss:  0.0001\n",
            "Iteration:  652 ...Training loss:  0.00024 ...Validation loss:  9e-05\n",
            "Iteration:  653 ...Training loss:  0.00024 ...Validation loss:  9e-05\n",
            "Iteration:  654 ...Training loss:  0.00024 ...Validation loss:  9e-05\n",
            "Iteration:  655 ...Training loss:  0.00023 ...Validation loss:  9e-05\n",
            "Iteration:  656 ...Training loss:  0.00023 ...Validation loss:  9e-05\n",
            "Iteration:  657 ...Training loss:  0.00023 ...Validation loss:  9e-05\n",
            "Iteration:  658 ...Training loss:  0.00022 ...Validation loss:  9e-05\n",
            "Iteration:  659 ...Training loss:  0.00022 ...Validation loss:  8e-05\n",
            "Iteration:  660 ...Training loss:  0.00021 ...Validation loss:  8e-05\n",
            "Iteration:  661 ...Training loss:  0.00021 ...Validation loss:  8e-05\n",
            "Iteration:  662 ...Training loss:  0.00021 ...Validation loss:  8e-05\n",
            "Iteration:  663 ...Training loss:  0.0002 ...Validation loss:  8e-05\n",
            "Iteration:  664 ...Training loss:  0.0002 ...Validation loss:  8e-05\n",
            "Iteration:  665 ...Training loss:  0.0002 ...Validation loss:  8e-05\n",
            "Iteration:  666 ...Training loss:  0.00019 ...Validation loss:  8e-05\n",
            "Iteration:  667 ...Training loss:  0.00019 ...Validation loss:  7e-05\n",
            "Iteration:  668 ...Training loss:  0.00019 ...Validation loss:  7e-05\n",
            "Iteration:  669 ...Training loss:  0.00018 ...Validation loss:  7e-05\n",
            "Iteration:  670 ...Training loss:  0.00018 ...Validation loss:  7e-05\n",
            "Iteration:  671 ...Training loss:  0.00018 ...Validation loss:  7e-05\n",
            "Iteration:  672 ...Training loss:  0.00018 ...Validation loss:  7e-05\n",
            "Iteration:  673 ...Training loss:  0.00017 ...Validation loss:  7e-05\n",
            "Iteration:  674 ...Training loss:  0.00017 ...Validation loss:  7e-05\n",
            "Iteration:  675 ...Training loss:  0.00017 ...Validation loss:  6e-05\n",
            "Iteration:  676 ...Training loss:  0.00016 ...Validation loss:  6e-05\n",
            "Iteration:  677 ...Training loss:  0.00016 ...Validation loss:  6e-05\n",
            "Iteration:  678 ...Training loss:  0.00016 ...Validation loss:  6e-05\n",
            "Iteration:  679 ...Training loss:  0.00016 ...Validation loss:  6e-05\n",
            "Iteration:  680 ...Training loss:  0.00015 ...Validation loss:  6e-05\n",
            "Iteration:  681 ...Training loss:  0.00015 ...Validation loss:  6e-05\n",
            "Iteration:  682 ...Training loss:  0.00015 ...Validation loss:  6e-05\n",
            "Iteration:  683 ...Training loss:  0.00015 ...Validation loss:  6e-05\n",
            "Iteration:  684 ...Training loss:  0.00014 ...Validation loss:  6e-05\n",
            "Iteration:  685 ...Training loss:  0.00014 ...Validation loss:  6e-05\n",
            "Iteration:  686 ...Training loss:  0.00014 ...Validation loss:  5e-05\n",
            "Iteration:  687 ...Training loss:  0.00014 ...Validation loss:  5e-05\n",
            "Iteration:  688 ...Training loss:  0.00013 ...Validation loss:  5e-05\n",
            "Iteration:  689 ...Training loss:  0.00013 ...Validation loss:  5e-05\n",
            "Iteration:  690 ...Training loss:  0.00013 ...Validation loss:  5e-05\n",
            "Iteration:  691 ...Training loss:  0.00013 ...Validation loss:  5e-05\n",
            "Iteration:  692 ...Training loss:  0.00013 ...Validation loss:  5e-05\n",
            "Iteration:  693 ...Training loss:  0.00012 ...Validation loss:  5e-05\n",
            "Iteration:  694 ...Training loss:  0.00012 ...Validation loss:  5e-05\n",
            "Iteration:  695 ...Training loss:  0.00012 ...Validation loss:  5e-05\n",
            "Iteration:  696 ...Training loss:  0.00012 ...Validation loss:  5e-05\n",
            "Iteration:  697 ...Training loss:  0.00012 ...Validation loss:  5e-05\n",
            "Iteration:  698 ...Training loss:  0.00011 ...Validation loss:  4e-05\n",
            "Iteration:  699 ...Training loss:  0.00011 ...Validation loss:  4e-05\n",
            "Iteration:  700 ...Training loss:  0.00011 ...Validation loss:  4e-05\n",
            "Iteration:  701 ...Training loss:  0.00011 ...Validation loss:  4e-05\n",
            "Iteration:  702 ...Training loss:  0.00011 ...Validation loss:  4e-05\n",
            "Iteration:  703 ...Training loss:  0.00011 ...Validation loss:  4e-05\n",
            "Iteration:  704 ...Training loss:  0.0001 ...Validation loss:  4e-05\n",
            "Iteration:  705 ...Training loss:  0.0001 ...Validation loss:  4e-05\n",
            "Iteration:  706 ...Training loss:  0.0001 ...Validation loss:  4e-05\n",
            "Iteration:  707 ...Training loss:  0.0001 ...Validation loss:  4e-05\n",
            "Iteration:  708 ...Training loss:  0.0001 ...Validation loss:  4e-05\n",
            "Iteration:  709 ...Training loss:  0.0001 ...Validation loss:  4e-05\n",
            "Iteration:  710 ...Training loss:  9e-05 ...Validation loss:  4e-05\n",
            "Iteration:  711 ...Training loss:  9e-05 ...Validation loss:  4e-05\n",
            "Iteration:  712 ...Training loss:  9e-05 ...Validation loss:  4e-05\n",
            "Iteration:  713 ...Training loss:  9e-05 ...Validation loss:  3e-05\n",
            "Iteration:  714 ...Training loss:  9e-05 ...Validation loss:  3e-05\n",
            "Iteration:  715 ...Training loss:  9e-05 ...Validation loss:  3e-05\n",
            "Iteration:  716 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  717 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  718 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  719 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  720 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  721 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  722 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  723 ...Training loss:  8e-05 ...Validation loss:  3e-05\n",
            "Iteration:  724 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  725 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  726 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  727 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  728 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  729 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  730 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  731 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  732 ...Training loss:  7e-05 ...Validation loss:  3e-05\n",
            "Iteration:  733 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  734 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  735 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  736 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  737 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  738 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  739 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  740 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  741 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  742 ...Training loss:  6e-05 ...Validation loss:  2e-05\n",
            "Iteration:  743 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  744 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  745 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  746 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  747 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  748 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  749 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  750 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  751 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  752 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  753 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  754 ...Training loss:  5e-05 ...Validation loss:  2e-05\n",
            "Iteration:  755 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  756 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  757 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  758 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  759 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  760 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  761 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  762 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  763 ...Training loss:  4e-05 ...Validation loss:  2e-05\n",
            "Iteration:  764 ...Training loss:  4e-05 ...Validation loss:  1e-05\n",
            "Iteration:  765 ...Training loss:  4e-05 ...Validation loss:  1e-05\n",
            "Iteration:  766 ...Training loss:  4e-05 ...Validation loss:  1e-05\n",
            "Iteration:  767 ...Training loss:  4e-05 ...Validation loss:  1e-05\n",
            "Iteration:  768 ...Training loss:  4e-05 ...Validation loss:  1e-05\n",
            "Iteration:  769 ...Training loss:  4e-05 ...Validation loss:  1e-05\n",
            "Iteration:  770 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  771 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  772 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  773 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  774 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  775 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  776 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  777 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  778 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  779 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  780 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  781 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  782 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  783 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  784 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  785 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  786 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  787 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  788 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  789 ...Training loss:  3e-05 ...Validation loss:  1e-05\n",
            "Iteration:  790 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  791 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  792 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  793 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  794 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  795 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  796 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  797 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  798 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  799 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  800 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  801 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  802 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  803 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  804 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  805 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  806 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  807 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  808 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  809 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  810 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  811 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  812 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  813 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  814 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  815 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  816 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  817 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  818 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  819 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  820 ...Training loss:  2e-05 ...Validation loss:  1e-05\n",
            "Iteration:  821 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  822 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  823 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  824 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  825 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  826 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  827 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  828 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  829 ...Training loss:  1e-05 ...Validation loss:  1e-05\n",
            "Iteration:  830 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  831 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  832 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  833 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  834 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  835 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  836 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  837 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  838 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  839 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  840 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  841 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  842 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  843 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  844 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  845 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  846 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  847 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  848 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  849 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  850 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  851 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  852 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  853 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  854 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  855 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  856 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  857 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  858 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  859 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  860 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  861 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  862 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  863 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  864 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  865 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  866 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  867 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  868 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  869 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  870 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  871 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  872 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  873 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  874 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  875 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  876 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  877 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  878 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  879 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  880 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  881 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  882 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  883 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  884 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  885 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  886 ...Training loss:  1e-05 ...Validation loss:  0.0\n",
            "Iteration:  887 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  888 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  889 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  890 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  891 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  892 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  893 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  894 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  895 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  896 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  897 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  898 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  899 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  900 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  901 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  902 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  903 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  904 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  905 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  906 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  907 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  908 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  909 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  910 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  911 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  912 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  913 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  914 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  915 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  916 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  917 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  918 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  919 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  920 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  921 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  922 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  923 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  924 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  925 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  926 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  927 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  928 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  929 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  930 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  931 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  932 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  933 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  934 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  935 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  936 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  937 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  938 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  939 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  940 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  941 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  942 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  943 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  944 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  945 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  946 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  947 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  948 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  949 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  950 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  951 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  952 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  953 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  954 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  955 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  956 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  957 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  958 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  959 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  960 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  961 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  962 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  963 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  964 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  965 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  966 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  967 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  968 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  969 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  970 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  971 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  972 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  973 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  974 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  975 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  976 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  977 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  978 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  979 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  980 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  981 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  982 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  983 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  984 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  985 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  986 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  987 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  988 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  989 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  990 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  991 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  992 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  993 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  994 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  995 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  996 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  997 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  998 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  999 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1000 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1001 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1002 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1003 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1004 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1005 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1006 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1007 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1008 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1009 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1010 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1011 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1012 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1013 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1014 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1015 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1016 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1017 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1018 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1019 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1020 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1021 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1022 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1023 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1024 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1025 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1026 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1027 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1028 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1029 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1030 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1031 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1032 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1033 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1034 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1035 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1036 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1037 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1038 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1039 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1040 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1041 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1042 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1043 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1044 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1045 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1046 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1047 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1048 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1049 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1050 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1051 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1052 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1053 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1054 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1055 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1056 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1057 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1058 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1059 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1060 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1061 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1062 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1063 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1064 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1065 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1066 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1067 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1068 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1069 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1070 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1071 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1072 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1073 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1074 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1075 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1076 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1077 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1078 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1079 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1080 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1081 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1082 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1083 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1084 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1085 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1086 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1087 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1088 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1089 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1090 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1091 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1092 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1093 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1094 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1095 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1096 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1097 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1098 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1099 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1100 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1101 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1102 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1103 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1104 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1105 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1106 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1107 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1108 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1109 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1110 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1111 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1112 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1113 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1114 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1115 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1116 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1117 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1118 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1119 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1120 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1121 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1122 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1123 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1124 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1125 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1126 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1127 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1128 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1129 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1130 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1131 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1132 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1133 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1134 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1135 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1136 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1137 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1138 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1139 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1140 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1141 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1142 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1143 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1144 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1145 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1146 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1147 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1148 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1149 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1150 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1151 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1152 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1153 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1154 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1155 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1156 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1157 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1158 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1159 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1160 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1161 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1162 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1163 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1164 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1165 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1166 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1167 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1168 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1169 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1170 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1171 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1172 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1173 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1174 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1175 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1176 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1177 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1178 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1179 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1180 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1181 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1182 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1183 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1184 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1185 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1186 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1187 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1188 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1189 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1190 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1191 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1192 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1193 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1194 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1195 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1196 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1197 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1198 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1199 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1200 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1201 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1202 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1203 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1204 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1205 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1206 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1207 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1208 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1209 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1210 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1211 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1212 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1213 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1214 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1215 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1216 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1217 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1218 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1219 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1220 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1221 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1222 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1223 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1224 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1225 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1226 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1227 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1228 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1229 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1230 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1231 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1232 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1233 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1234 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1235 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1236 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1237 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1238 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1239 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1240 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1241 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1242 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1243 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1244 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1245 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1246 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1247 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1248 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1249 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1250 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1251 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1252 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1253 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1254 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1255 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1256 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1257 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1258 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1259 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1260 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1261 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1262 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1263 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1264 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1265 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1266 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1267 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1268 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1269 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1270 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1271 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1272 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1273 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1274 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1275 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1276 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1277 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1278 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1279 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1280 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1281 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1282 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1283 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1284 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1285 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1286 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1287 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1288 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1289 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1290 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1291 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1292 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1293 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1294 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1295 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1296 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1297 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1298 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1299 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1300 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1301 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1302 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1303 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1304 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1305 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1306 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1307 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1308 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1309 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1310 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1311 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1312 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1313 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1314 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1315 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1316 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1317 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1318 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1319 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1320 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1321 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1322 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1323 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1324 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1325 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1326 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1327 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1328 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1329 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1330 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1331 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1332 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1333 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1334 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1335 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1336 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1337 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1338 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1339 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1340 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1341 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1342 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1343 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1344 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1345 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1346 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1347 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1348 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1349 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1350 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1351 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1352 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1353 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1354 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1355 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1356 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1357 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1358 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1359 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1360 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1361 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1362 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1363 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1364 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1365 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1366 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1367 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1368 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1369 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1370 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1371 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1372 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1373 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1374 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1375 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1376 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1377 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1378 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1379 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1380 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1381 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1382 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1383 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1384 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1385 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1386 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1387 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1388 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1389 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1390 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1391 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1392 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1393 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1394 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1395 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1396 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1397 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1398 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1399 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1400 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1401 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1402 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1403 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1404 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1405 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1406 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1407 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1408 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1409 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1410 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1411 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1412 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1413 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1414 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1415 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1416 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1417 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1418 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1419 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1420 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1421 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1422 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1423 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1424 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1425 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1426 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1427 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1428 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1429 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1430 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1431 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1432 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1433 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1434 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1435 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1436 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1437 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1438 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1439 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1440 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1441 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1442 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1443 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1444 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1445 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1446 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1447 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1448 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1449 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1450 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1451 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1452 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1453 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1454 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1455 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1456 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1457 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1458 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1459 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1460 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1461 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1462 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1463 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1464 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1465 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1466 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1467 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1468 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1469 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1470 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1471 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1472 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1473 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1474 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1475 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1476 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1477 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1478 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1479 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1480 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1481 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1482 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1483 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1484 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1485 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1486 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1487 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1488 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1489 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1490 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1491 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1492 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1493 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1494 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1495 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1496 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1497 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1498 ...Training loss:  0.0 ...Validation loss:  0.0\n",
            "Iteration:  1499 ...Training loss:  0.0 ...Validation loss:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpXbz2mfYBIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "62ebc4c0-ccbd-43fe-f38a-bb4023597c04"
      },
      "source": [
        "plt.plot(losses['train'], label='Training loss')\n",
        "plt.plot(losses['validation'], label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f15a2d66750>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekO6tjpot4NU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}